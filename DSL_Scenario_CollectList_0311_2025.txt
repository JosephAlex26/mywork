#scenario_03112025
#approach
#1. drop duplicates
#2. groupBy sell date, count list with product rename as products
#3. count the product and rename as null_sell

from pyspark.sql import *
from pyspark.sql.types import *
from pyspark.sql.functions import *

data = [('2020-05-30','Headphone'),('2020-06-01','Pencil'),('2020-06-02','Mask'),('2020-05-30','Basketball'),('2020-06-01','Book'),('2020-06-02','Mask'),('2020-05-30','T-Shirt')]
columns = ["sell_date",'product']

df = spark.createDataFrame(data,schema=columns)
df.show()

#drop duplicates

dfd = df.dropDuplicates()
dfd.show()

#collect_list

finaldf = dfd.groupBy("sell_date").agg(collect_list ("product").alias("products"),count("product").alias("null_sell"))
finaldf.show()